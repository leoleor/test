import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as d,o as h,c as o,b as e,d as t,e as i,a as n,f as a}from"./app-889e667f.js";const p="/test/images/http/http1.1_长短连接.png",P="/test/images/http/http2.0_多路复用.png",c="/test/images/http/网络延时.png",s="/test/images/http/TCPIP网络模型对比.png",l="/test/images/http/http3.0_连接更快.png",H="/test/images/http/http3.0_连接对比.png",C="/test/images/http/TCP四元组.png",f={},g=a('<div class="hint-container tip"><p class="hint-container-title">省流总结</p><h3 id="http1-0和http1-1" tabindex="-1"><a class="header-anchor" href="#http1-0和http1-1" aria-hidden="true">#</a> HTTP1.0和HTTP1.1</h3><ol><li>HTTP1.0默认是<code>短连接</code>。每次与服务器交互，都需要新开一个TCP连接；<br> HTTP1.1默认是<code>长连接</code>。只要客户端服务端没有断开TCP连接，就一直保持连接，可以发送多次HTTP请求。(目前浏览器中对于同一个域名，默认允许同时建立 6 个 TCP 持久连接)</li><li>HTTP1.1支持<code>断点续传</code>，只发送header信息（不带任何body信息）</li><li>HTTP1.0缓存处理：expires，HTTP1.1引入更丰富的缓存字段如：cache-control</li></ol><h3 id="http1-1和http2-0" tabindex="-1"><a class="header-anchor" href="#http1-1和http2-0" aria-hidden="true">#</a> HTTP1.1和HTTP2.0</h3><ol><li>HTTP1.1请求头header以纯文本传输；HTTP2.0支持<code>头部压缩</code></li><li>HTTP1.1是以<code>文本格式</code>传输数据，HTTP2.0改用<code>二进制格式</code>传输数据</li><li>HTTP1.1需要等上一个请求的响应数据回来后才能发送另一个请求；<br> HTTP2.0设计了 <code>Stream</code> 概念，多个 Stream 复用同一个TCP连接，并发处理多个请求</li><li>HTTP2.0支持<code>服务端推送</code></li></ol><p>HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。</p><ol><li>TCP的队头阻塞并没有彻底解决</li><li>TCP以及TCP+TLS建立连接的延时</li><li>网络迁移需要重新连接</li></ol><h3 id="http2-0和http3-0" tabindex="-1"><a class="header-anchor" href="#http2-0和http3-0" aria-hidden="true">#</a> HTTP2.0和HTTP3.0</h3><ol><li>HTTP3.0弃用TCP，基于UDP实现了<code>QUIC协议</code>，彻底解决了TCP层的队头堵塞</li><li>更快建立连接</li><li>通过连接ID，实现连接迁移；</li></ol></div>',1),u={href:"https://juejin.cn/post/6995109407545622542",target:"_blank",rel:"noopener noreferrer"},m={href:"https://juejin.cn/post/7001510315514937375",target:"_blank",rel:"noopener noreferrer"},b=a('<h2 id="http-0-9" tabindex="-1"><a class="header-anchor" href="#http-0-9" aria-hidden="true">#</a> HTTP/0.9</h2><p>HTTP 的最早版本诞生在 1991 年。这个最早版本和现在比起来极其简单，没有 HTTP 头，没有状态码，甚至版本号也没有，后来它的版本号才被定为 0.9 来和其他版本的 HTTP 区分。HTTP/0.9 只支持一种方法—— Get，请求只有一行。</p><h2 id="http-1-0" tabindex="-1"><a class="header-anchor" href="#http-1-0" aria-hidden="true">#</a> HTTP/1.0</h2><p>HTTP1.0最早在网页中使用是在1996年。随着新兴网络发展，首先在浏览器中展示的不单是 HTML 文件了，还包括了 JavaScript、CSS、图片、音频、视频等不同类型的文件。服务器不知道如文件编码、文件类型，因此直接返回数据给浏览器...为了满足传输多种类型文件的需求，HTTP1.0引入了<code>请求头</code> 和 <code>响应头</code></p><h2 id="http-1-1" tabindex="-1"><a class="header-anchor" href="#http-1-1" aria-hidden="true">#</a> HTTP/1.1</h2><h3 id="http1-1在http1-0上的改进" tabindex="-1"><a class="header-anchor" href="#http1-1在http1-0上的改进" aria-hidden="true">#</a> HTTP1.1在HTTP1.0上的改进</h3><h4 id="改进持久连接" tabindex="-1"><a class="header-anchor" href="#改进持久连接" aria-hidden="true">#</a> 😊改进持久连接</h4><figure><img src="'+p+'" alt="长短连接" tabindex="0" loading="lazy"><figcaption>长短连接</figcaption></figure><p>HTTP/1.0 每进行一次 HTTP 通信，都需要经历建立 TCP 连接、传输 HTTP 数据和断开 TCP 连接三个阶段。如果一个页面包含了几百个外部引用的资源文件，在下载每个文件的时候，都需要经历建立 TCP 连接、传输数据和断开连接这样的步骤，无疑会增加大量无谓的开销。</p><p>为了解决这个问题，HTTP/1.1 中增加了<code>持久连接</code>的方法，它的特点是在<code>一个 TCP 连接上可以传输多个 HTTP 请求</code>，只要浏览器或者服务器没有明确断开连接，那么该 TCP 连接会一直保持。</p><p>持久连接在 HTTP/1.1 中是默认开启的，所以你不需要专门为了持久连接去 HTTP 请求头设置信息，如果你不想要采用持久连接，可以在 HTTP 请求头中加上Connection: close。目前谷歌浏览器中对于同一个域名，默认允许同时建立 6 个 TCP 持久连接。</p><h4 id="不成熟的-http-管线化" tabindex="-1"><a class="header-anchor" href="#不成熟的-http-管线化" aria-hidden="true">#</a> 😊不成熟的 HTTP 管线化</h4><p>持久连接虽然能减少 TCP 的建立和断开次数，但是它需要等待前面的请求返回之后，才能进行下一次请求。如果 TCP 通道中的某个请求因为某些原因没有及时返回，那么就会阻塞后面的所有请求，这就是著名的队头阻塞(应用层)的问题。</p><p>HTTP/1.1 中试图通过管线化的技术来解决队头阻塞的问题。HTTP/1.1 中的管线化是指将多个 HTTP 请求整批提交给服务器的技术，虽然可以整批发送请求，不过服务器依然需要根据请求顺序来回复浏览器的请求。HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞</p><p>FireFox、Chrome 都做过管线化的试验，但是由于各种原因，它们最终都放弃了管线化技术。</p><h4 id="提供虚拟主机的支持" tabindex="-1"><a class="header-anchor" href="#提供虚拟主机的支持" aria-hidden="true">#</a> 😊提供虚拟主机的支持</h4><h4 id="对动态生成的内容提供了完美支持" tabindex="-1"><a class="header-anchor" href="#对动态生成的内容提供了完美支持" aria-hidden="true">#</a> 😊对动态生成的内容提供了完美支持</h4><h4 id="客户端-cookie、安全机制" tabindex="-1"><a class="header-anchor" href="#客户端-cookie、安全机制" aria-hidden="true">#</a> 😊 客户端 Cookie、安全机制</h4><h4 id="断点续传" tabindex="-1"><a class="header-anchor" href="#断点续传" aria-hidden="true">#</a> 😊断点续传</h4><p>要实现断点续传的功能，通常都需要客户端记录下当前的下载进度，并在需要续传的时候通知服务端本次需要下载的内容片段。</p><p>HTTP1.1协议（RFC2616）中定义了断点续传相关的HTTP头 Range和Content-Range字段，一个最简单的断点续传实现大概如下：</p><ol><li>客户端下载一个1024K的文件，已经下载了其中512K</li><li>网络中断，客户端请求续传，因此需要在HTTP头中申明本次需要续传的片段：<code>Range:bytes=512000-</code> 这个头通知服务端从文件的512K位置开始传输文件</li><li>服务端收到断点续传请求，从文件的512K位置开始传输，并且在HTTP头中增加：<code>Content-Range:bytes 512000-/1024000</code> 并且此时服务端返回的HTTP状态码应该是<code>206</code>，而不是200。</li></ol><h3 id="​http1-1-性能瓶颈" tabindex="-1"><a class="header-anchor" href="#​http1-1-性能瓶颈" aria-hidden="true">#</a> ​HTTP1.1 性能瓶颈</h3><h4 id="请求-响应头部-header-未经压缩-首部信息越多延迟越大-只能压缩-body-的部分" tabindex="-1"><a class="header-anchor" href="#请求-响应头部-header-未经压缩-首部信息越多延迟越大-只能压缩-body-的部分" aria-hidden="true">#</a> 😕请求 / 响应头部（Header）未经压缩，首部信息越多延迟越大(只能压缩 Body 的部分)；</h4><h4 id="响应头的对头阻塞没有彻底解决" tabindex="-1"><a class="header-anchor" href="#响应头的对头阻塞没有彻底解决" aria-hidden="true">#</a> 😕响应头的对头阻塞没有彻底解决；</h4><h4 id="没有请求优先级控制" tabindex="-1"><a class="header-anchor" href="#没有请求优先级控制" aria-hidden="true">#</a> 😕没有请求优先级控制；</h4><h4 id="请求只能从客户端开始-服务器只能被动响应。" tabindex="-1"><a class="header-anchor" href="#请求只能从客户端开始-服务器只能被动响应。" aria-hidden="true">#</a> 😕请求只能从客户端开始，服务器只能被动响应。</h4><h2 id="http-2-0" tabindex="-1"><a class="header-anchor" href="#http-2-0" aria-hidden="true">#</a> HTTP/2.0</h2><h3 id="http2-0在http1-1上的改进" tabindex="-1"><a class="header-anchor" href="#http2-0在http1-1上的改进" aria-hidden="true">#</a> HTTP2.0在HTTP1.1上的改进</h3><h4 id="头部压缩" tabindex="-1"><a class="header-anchor" href="#头部压缩" aria-hidden="true">#</a> 😊头部压缩</h4><p>HTTP 协议的报文是由「Header + Body」构成的，对于 Body 部分，HTTP/1.1 协议可以使用头字段 「Content-Encoding」指定 Body 的压缩方式，比如用 gzip 压缩，这样可以节约带宽，但报文中的另外一部分 Header，是没有针对它的优化手段。</p><p>HTTP/2 没使用常见的 gzip 压缩方式来压缩头部，而是开发了<code>HPACK</code>算法</p><h4 id="二进制帧" tabindex="-1"><a class="header-anchor" href="#二进制帧" aria-hidden="true">#</a> 😊二进制帧</h4><p>HTTP/2 厉害的地方在于将 HTTP/1 的文本格式改成<code>二进制格式</code>传输数据，极大提高了 HTTP 传输效率，而且二进制数据使用位运算能高效解析。</p><h4 id="多路复用-并发传输" tabindex="-1"><a class="header-anchor" href="#多路复用-并发传输" aria-hidden="true">#</a> 😊多路复用，并发传输</h4><p>知道了 HTTP/2 的帧结构后，我们再来看看它是如何实现并发传输的。</p><p>我们都知道 HTTP/1.1 的实现是基于请求-响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了队头阻塞的问题。</p><p>而 HTTP/2 就很牛逼了，通过 Stream 这个设计，多个 Stream 复用一条 TCP 连接，达到并发的效果，解决了 HTTP/1.1 队头阻塞的问题，提高了 HTTP 传输的吞吐量。</p><p>为了理解 HTTP/2 的并发是怎样实现的，我们先来理解 HTTP/2 中的 Stream、Message、Frame 这 3 个概念。</p><figure><img src="'+P+'" alt="多路复用" tabindex="0" loading="lazy"><figcaption>多路复用</figcaption></figure><p>你可以从上图中看到：</p><ul><li>1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术；</li><li>Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成；</li><li>Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）；</li></ul><p>因此，我们可以得出个结论：多个 Stream 跑在一条 TCP 连接，同一个 HTTP 请求与响应是跑在同一个 Stream 中，HTTP 消息可以由多个 Frame 构成， 一个 Frame 可以由多个 TCP 报文构成。</p><p>HTTP/2 通过 Stream 实现的<code>并发</code>，比 HTTP/1.1 通过 TCP 连接实现并发要牛逼的多，<code>因为当 HTTP/2 实现 100 个并发 Stream 时，只需要建立一次 TCP 连接，而 HTTP/1.1 需要建立 100 个 TCP 连接，每个 TCP 连接都要经过 TCP 握手、慢启动以及 TLS 握手过程，这些都是很耗时的</code>。</p><p>HTTP/2 还可以对每个 Stream 设置不同<code>优先级</code>，帧头中的「标志位」可以设置优先级，比如客户端访问 HTML/CSS 和图片资源时，希望服务器先传递 HTML/CSS，再传图片，那么就可以通过设置 Stream 的优先级来实现，以此提高用户体验。</p>',45),_=a('<h5 id="与http1-1管线化的区别" tabindex="-1"><a class="header-anchor" href="#与http1-1管线化的区别" aria-hidden="true">#</a> ❓与HTTP1.1管线化的区别：</h5><p>HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是没有解决响应的队头阻塞，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 <code>HTTP层队头阻塞</code>。</p><p>HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是一旦发生丢包，就会阻塞住所有的 HTTP 请求，这属于 <code>TCP层队头阻塞</code>。</p><blockquote><p>HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。</p></blockquote><p>(使用 HTTP/1.1 时，浏览器为每个域名开启了 6 个 TCP 连接，如果其中的 1 个 TCP 连接发生了队头阻塞，那么其他的 5 个连接依然可以继续传输数据；而HTTP/2.0是一个TCP连接的，所以随着丢包率的增加，HTTP/2 的传输效率也会越来越差。有测试数据表明，当系统达到了 2% 的丢包率时，HTTP/1.1 的传输效率反而比 HTTP/2 表现得更好)</p><h4 id="服务器推送" tabindex="-1"><a class="header-anchor" href="#服务器推送" aria-hidden="true">#</a> 😊服务器推送</h4><p>HTTP2让服务器可以将响应数据主动推送到客户端缓存中</p><h3 id="美中不足的http2-0" tabindex="-1"><a class="header-anchor" href="#美中不足的http2-0" aria-hidden="true">#</a> 美中不足的HTTP2.0</h3><p>主要是底层的tcp协议造成的</p><h4 id="tcp-的队头阻塞并没有彻底解决" tabindex="-1"><a class="header-anchor" href="#tcp-的队头阻塞并没有彻底解决" aria-hidden="true">#</a> 😕TCP 的队头阻塞并没有彻底解决</h4><p>因为 TCP 是<code>字节流协议</code>，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是请求被阻塞了。</p><h4 id="tcp-以及-tcp-tls-建立连接的延时" tabindex="-1"><a class="header-anchor" href="#tcp-以及-tcp-tls-建立连接的延时" aria-hidden="true">#</a> 😕TCP 以及 TCP+TLS 建立连接的延时</h4><p>网络延迟又称为 RTT（Round Trip Time）。我们把从浏览器发送一个数据包到服务器，再从服务器返回数据包到浏览器的整个往返时间称为 RTT（如下图）。RTT 是反映网络性能的一个重要指标。</p><figure><img src="'+c+'" alt="网络延时" tabindex="0" loading="lazy"><figcaption>网络延时</figcaption></figure><p>我们知道 HTTP/1 和 HTTP/2 都是使用 TCP 协议来传输的，而如果使用 HTTPS 的话，还需要使用 TLS 协议进行安全传输，而使用 TLS 也需要一个握手过程，这样就需要有两个握手延迟过程。</p><ul><li>在建立 TCP 连接的时候，需要和服务器进行三次握手来确认连接成功，也就是说需要在消耗完 1.5 个 RTT 之后才能进行数据传输。</li><li>进行 TLS 连接，TLS 有两个版本——TLS1.2 和 TLS1.3，每个版本建立连接所花的时间不同，大致是需要 1～2 个 RTT，关于 HTTPS 我们到后面到安全模块再做详细介绍</li></ul><p>总之，在传输数据之前，我们需要花掉 3～4 个 RTT。如果浏览器和服务器的物理距离较近，那么 1 个 RTT 的时间可能在 10 毫秒以内，也就是说总共要消耗掉 30～40 毫秒。这个时间也许用户还可以接受，但如果服务器相隔较远，那么 1 个 RTT 就可能需要 100 毫秒以上了，这种情况下整个握手过程需要 300～400 毫秒，这时用户就能明显地感受到“慢”了。</p><h4 id="网络迁移需要重新连接" tabindex="-1"><a class="header-anchor" href="#网络迁移需要重新连接" aria-hidden="true">#</a> 😕网络迁移需要重新连接</h4><p>一个 TCP 连接是由四元组（源 IP 地址，源端口，目标 IP 地址，目标端口）确定的，这意味着如果 IP 地址或者端口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WiFi。</p><h2 id="http-3-0" tabindex="-1"><a class="header-anchor" href="#http-3-0" aria-hidden="true">#</a> HTTP/3.0</h2><p>为了解决TCP协议固有的问题，HTTP/3.0把传输层协议换成了UDP！</p><p>我们深知，UDP 是一个简单、不可靠的传输协议，而且是 UDP 包之间是无序的，也没有依赖关系。</p><p>而且，UDP 是不需要连接的，也就不需要握手和挥手的过程，所以天然的就比 TCP 快。</p><p>当然，HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 QUIC 协议，它具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了，所以不用担心数据包丢失的问题。</p><h3 id="彻底解决队头阻塞" tabindex="-1"><a class="header-anchor" href="#彻底解决队头阻塞" aria-hidden="true">#</a> 彻底解决队头阻塞</h3><p>首先了解<code>UDP是面向报文的协议</code>和<code>TCP是面向字节流的协议</code></p>',26),x={href:"https://xiaolincoding.com/network/3_tcp/tcp_stream.html#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%AD%97%E8%8A%82%E6%B5%81",target:"_blank",rel:"noopener noreferrer"},S=a('<p>QUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。</p><p>由于 QUIC 使用的传输协议是 UDP，UDP 不关心数据包的顺序，如果数据包丢失，UDP 也不关心。</p><p>不过 QUIC 协议会保证数据包的可靠性，每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。</p><p>而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。</p><p>所以，<code>QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响</code>。</p><h3 id="更快的连接建立" tabindex="-1"><a class="header-anchor" href="#更快的连接建立" aria-hidden="true">#</a> 更快的连接建立</h3><figure><img src="'+s+'" alt="TCP/IP网络模型" tabindex="0" loading="lazy"><figcaption>TCP/IP网络模型</figcaption></figure><p>对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。</p><p>HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。</p><p>但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，如下图：</p><figure><img src="'+l+'" alt="连接更快" tabindex="0" loading="lazy"><figcaption>连接更快</figcaption></figure><p>甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。</p><p>如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）：</p><figure><img src="'+H+'" alt="连接对比" tabindex="0" loading="lazy"><figcaption>连接对比</figcaption></figure><h3 id="连接迁移" tabindex="-1"><a class="header-anchor" href="#连接迁移" aria-hidden="true">#</a> 连接迁移</h3><p>基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。</p><figure><img src="'+C+'" alt="TCP四元组" tabindex="0" loading="lazy"><figcaption>TCP四元组</figcaption></figure><p>那么<code>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接</code>。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。</p><p>而 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过<code>连接 ID</code>来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了<code>连接迁移</code>的功能。</p><p>所以， QUIC 是一个在 UDP 之上的<code>伪</code> TCP + TLS + HTTP/2 的多路复用的协议。</p><p>QUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP包，然后被丢弃。</p><p>HTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。</p>',22);function I(U,D){const T=d("ExternalLinkIcon");return h(),o("div",null,[g,e("p",null,[e("a",u,[t("解读 HTTP1/HTTP2/HTTP3"),i(T)])]),e("p",null,[e("a",m,[t("一文总结HTTP1.0，HTTP1.1，HTTP2，HTTP3，面试强心剂"),i(T)])]),b,n(` a. 首先，浏览器准备好请求数据，包括了请求行、请求头等信息，如果是 POST 方法，那么还要有请求体。
b. 这些数据经过二进制分帧层处理之后，会被转换为一个个带有请求 ID 编号的帧，通过协议栈将这些帧发送给服务器。
c. 服务器接收到所有帧之后，会将所有相同 ID 的帧合并为一条完整的请求信息。
d. 然后服务器处理该条请求，并将处理的响应行、响应头和响应体分别发送至二进制分帧层。
e. 同样，二进制分帧层会将这些响应数据转换为一个个带有请求 ID 编号的帧，经过协议栈发送给浏览器。
f. 浏览器接收到响应帧之后，会根据 ID 编号将帧的数据提交给对应的请求
通过二进制分帧层将请求转成一个个带有ID编号的帧，经过服务器处理后，二进制分帧层又将这些响应数据转换为一个个带有请求 ID 编号的帧，经过协议栈发送给浏览器，浏览器接收到响应帧之后，会根据 ID 编号将帧的数据提交给对应的请求。 `),_,e("p",null,[e("a",x,[t("如何理解TCP是面向字节流协议"),i(T)])]),S])}const R=r(f,[["render",I],["__file","httpVersion.html.vue"]]);export{R as default};
